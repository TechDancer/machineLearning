{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Engineering 1.0\n",
    "\n",
    "As I started playing w/ logistic regression to build a Lada Gaga song detector, I found that the # of features is too large to compute.  Moreso, the feature grid was mostly sparse and mostly useless since it was based on a basic word count vectorization.  (See the nice example using Naive Bayes from Mike: https://github.com/qzmeng/ail/blob/master/training.ipynb)\n",
    "\n",
    "There is some good scikit info on managing this:\n",
    "http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py  \n",
    "\n",
    "This is a survey of my findings\n",
    "\n",
    "- Using 300 songs (1/2 Lady Gaga 1/2 Clash), we counted words\n",
    "- 4000+ words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table {margin-left: 0 !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>table {margin-left: 0 !important;}</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tons of words only used once, a few used many times, the rest are common words counted alot of times \n",
    "\n",
    "| Times Counted | Frequency | Meaning\n",
    "|---------------|-----------|----\n",
    "|1: | 1992   |  1992 words appeared once\n",
    "|2: | 572\n",
    "|3: | 296\n",
    "|4: | 212    | 212 words appeared 4 times\n",
    "|5: | 123   \n",
    "|.. | ..\n",
    "|25-600 | ~1  | Many diff words appeared a many times\n",
    "\n",
    "\n",
    "\n",
    "Most frequent words are maybe useless conjugation:\n",
    "\n",
    "| Word [Index] | count | Word [Index] | count |\n",
    "|--------  |------  |----------- |----  |\n",
    "|in  [1155]    |           ct: 321      | on  [1581]    |         ct:329       |\n",
    "|love  [1356]     |          ct: 331     |    that  [2288]         |      ct:366       |\n",
    "|oh  [1573]      |           ct: 394     |    be  [166]          |        ct:394       |\n",
    "|your  [2612]    |           ct: 487     |     my  [1512]        |         ct:489      | \n",
    "|to  [2331]       |          ct: 495    |     and  [69]          |        ct:497     |  \n",
    "|it  [1185]      |           ct: 550    |     me  [1414]       |          ct:589    |   \n",
    "|the  [2289]     |           ct: 980   |      you  [2609]        |        ct:1260  |\n",
    "\n",
    "\n",
    "Lots of words only used once:  \n",
    "\n",
    "| Word [Index] | count | Word [Index] | count |\n",
    "|--------  |------  |----------- |----  |\n",
    "|typical  [2399]    |       ct: 1   |       six  [2046]           |    ct:1       |  \n",
    "|hits  [1080]        |      ct: 1    |      photo  [1674]          |   ct:1       |  \n",
    "|screaming  [1940]  |       ct: 1    |      atmosphere  [114]      |   ct:1      |   \n",
    "|fit  [814]         |       ct: 1    |      rootiful  [1877]      |    ct:1       |  \n",
    "\n",
    "Useful words maybe in middle of count frequency?\n",
    "\n",
    "| Word [Index] | count | Word [Index] | count |\n",
    "|--------  |------  |----------- |----  |\n",
    "|superstar  [2215]    |     ct: 57      |   fame  [746]         |      ct:57        \n",
    "|time  [2328]         |     ct: 58        | think  [2300]        |     ct:58        \n",
    "|now  [1558]          |     ct: 59      |   tonight  [2341]      |     ct:60        \n",
    "|gaga  [884]            |   ct: 61         |  heart  [1042]      |       ct:61  \n",
    "\n",
    "One problem is we are counting total # of words.  I imagine in a song, the same words repeat alot so imagine if the chorus is \"love love love... all you need is love love love\" you are getting like 20 hits from one song.    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, {0: 0, 1: 12, 3: 1, 5: 2, 6: 1, 8: 2, 9: 2})\n"
     ]
    }
   ],
   "source": [
    "import requests, pandas, io, numpy, argparse, math\n",
    "from myutils import *\n",
    "\n",
    "# copied code from meng - pull in songclass/* lady gaga/class music text data\n",
    "def getGagaData(maxrows=200,maxfeatures=4000,gtype=None):\n",
    "    import random, sklearn, sklearn.feature_extraction.text, sklearn.naive_bayes\n",
    "    def append_data(ds,dir,label,size):\n",
    "        filenames=os.listdir(dir)\n",
    "        for i,fn in enumerate(filenames):\n",
    "            if (i>=size):\n",
    "                break            \n",
    "            data=open(dir+'/'+fn,'r').read()\n",
    "            ds.append((data,label))\n",
    "        return ds\n",
    "\n",
    "    dataset=[]\n",
    "    if (gtype == 1 or gtype == None):\n",
    "        append_data(dataset,'songclass/lyrics/gaga',1,maxrows/2)\n",
    "    if (gtype == 0 or gtype == None):     \n",
    "        append_data(dataset,'songclass/lyrics/clash',0,maxrows/2)\n",
    "    data,target=zip(*dataset)\n",
    "    vec=sklearn.feature_extraction.text.CountVectorizer()\n",
    "    mat=vec.fit_transform(data)\n",
    "    yarr = list(target)\n",
    "    data = mat.toarray()\n",
    "    labels = vec.get_feature_names()[0:maxfeatures]\n",
    "    \n",
    "    if (maxfeatures > len(data[0])):\n",
    "        maxfeatures = len(data[0]) \n",
    "    data = data[:,0:maxfeatures]\n",
    "    return data,yarr,labels\n",
    "\n",
    "def countWords(trainingMatrix, labels):\n",
    "    counts = {0:0}\n",
    "    words = {}\n",
    "    for i,col in enumerate(trainingMatrix.T):   # transpose to inspect word by word\n",
    "        sum = numpy.sum(col)\n",
    "        if (sum not in counts):\n",
    "            counts[sum] = 1\n",
    "        else:\n",
    "            counts[sum] = counts[sum] + 1\n",
    "        words[labels[i]+'  ['+str(i)+']'] = sum\n",
    "    print (i, counts)\n",
    "    import operator\n",
    "    sorted_words = sorted(words.items(), key=operator.itemgetter(1))\n",
    "    return numpy.asmatrix(sorted_words)    \n",
    "\n",
    "trainingMatrix1,yArr1,labels1 = getGagaData(maxrows=10,maxfeatures=20, gtype=0)  # gaga data only for now 10 rows\n",
    "mGaga = countWords(trainingMatrix1, labels1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
