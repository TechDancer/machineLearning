{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to TensorFlow\n",
    "\n",
    "Note I am reading the book as my guide -- https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291 - first half of book is really good.  Tensorflow area starts pretty good, but then dives a bit too opaquely into the high level Deep Neural Net API.  Its quite hard to understand whats happening -- you really need a bit more low level code samples of implementing backprop and layers with smaller examples I think.\n",
    "\n",
    "Anyways the goal here will be to explore building similar tools as I've done before:  \n",
    "- Basic logistic regression solver\n",
    "- Gradient Descent solver\n",
    "- Lady Gaga example applied to TF\n",
    "- GPU testing\n",
    "\n",
    "Then to move onto the next major area: Neural Networks (and to competitive frameworks like PyTorch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow requires you to wrap your variables and methods into their own custom structures.  A few caveats:  \n",
    "- TF wants stuff in a different row/matrix orientation than SciKit.  Keeping matrix shapes straight is key to saving time (debugging).\n",
    "- TF seems hard to debug since you wrap stuff and evaluate later in a graph (asyncronous almost)\n",
    "- TF graph gui stuff looks slick\n",
    "- Its not so intuitive as a Py declarative programmer (there is an eager-eval mode, but doesn't mix well)\n",
    "\n",
    "Below is a simple Logistic Regression using Batch Gradient Descent in Tensor Flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta computed:  ['0.6762', '-0.8275']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from myutils import gf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "n_epochs = 400\n",
    "learning_rate = 0.01\n",
    "\n",
    "xs = np.array([[10,1],[11,2],[1,6]])   # dummy sample  (high, high, low)\n",
    "ys = np.array([[1],[1],[0]])           # dummy results (correlates high count as positive, so 1,1,0 results)\n",
    "\n",
    "X = tf.constant(xs, dtype=tf.float32, name='X')   # wrap in TF vanilla consts\n",
    "y = tf.constant(ys, dtype=tf.float32, name='y')   \n",
    "\n",
    "theta = tf.Variable(tf.constant([[0.1],[0.1]]), name='theta')  # TF \"variable\"\n",
    "y_pred = tf.sigmoid(tf.matmul(X, theta, name='predictions'))  # wrap in TF sigmoid\n",
    "\n",
    "with tf.name_scope(\"loss\"):                # named scope (for graph imagery gropuing)\n",
    "    error = y_pred - y                     # error used in next scope\n",
    "    ll = tf.reduce_mean(tf.losses.log_loss(y,y_pred), name='log_loss')  # std log_loss function, not used?\n",
    "\n",
    "with tf.name_scope(\"gradients\"):\n",
    "    gradients = 2.0/len(ys) * tf.matmul(tf.transpose(X), error)         # std partial deriv/gradient formula \n",
    "    training_op = tf.assign(theta, theta - learning_rate * gradients)   # \"training_op\" is called later\n",
    "\n",
    "init = tf.global_variables_initializer()   # boilerplate init\n",
    "\n",
    "with tf.Session() as sess:                 # this is where the TF stuff actually runs\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):          # GD loop\n",
    "        sess.run(training_op)              # each loop calls \"training_op\" again which assigns the theta\n",
    "    best_theta = theta.eval()              # fetch theta array\n",
    "    print('theta computed: ', gf(best_theta))            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple example above shows how a simple logistical regression example is calculated in TensorFlow.   \n",
    "\n",
    "- There are 2 features, and 3 training examples (3x2 matrix).\n",
    "- Imagine if this is a Female test (1 is female, 0 is male).  1st feature is Hair Length, 2nd feature is Foot Size\n",
    "- First 2 examples have long hair, small feet.  3rd example has short hair, big feet.\n",
    "- Expected Y outputs are 1,1,0 -- first 2 examples are female, last is male.\n",
    "\n",
    "The model trains itself and weighs Feature1 +0.67 on hair length, and -0.83 on shoe size to feed the sigmoid function to determine >0.5 and map to Female(1) or <0.5 Male(0).\n",
    "\n",
    "---\n",
    "\n",
    "## Re-doing the Lady Gaga Classifier with a little bit of TF\n",
    "\n",
    "Here we go, adapted to solve our favorite dummy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gaga test set 175 docs\n",
      "WARNING:root:non gaga test set 128 docs\n",
      "WARNING:root:feature reduce KBest: (213, 4000)\n",
      "WARNING:root:KBest 500 applied (213, 500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD Loop 0 Log_Loss 0.59850425\n",
      "GD Loop 500 Log_Loss 0.4192724\n",
      "GD Loop 1000 Log_Loss 0.34695074\n",
      "GD Loop 1500 Log_Loss 0.30071217\n",
      "GD Loop 2000 Log_Loss 0.26779503\n",
      "\n",
      "trained theta weights: ['-0.0209', '-0.0039', '-0.0069', '-0.0125', '-0.0018', '-0.0244', '0.0235', '0.0125', '0.0118', '-0.1697', '0.0118', '-0.0051', '0.0354', '0.0138', '0.0438', '-0.0172', '0.0424', '-0.0088', '0.0309', '0.0315', '...']\n",
      "\n",
      "Training results: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word/feature</th>\n",
       "      <td>1977</td>\n",
       "      <td>99999</td>\n",
       "      <td>adds</td>\n",
       "      <td>advertising</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>age</td>\n",
       "      <td>ah</td>\n",
       "      <td>aha</td>\n",
       "      <td>aimin</td>\n",
       "      <td>ain</td>\n",
       "      <td>ak</td>\n",
       "      <td>alike</td>\n",
       "      <td>amen</td>\n",
       "      <td>american</td>\n",
       "      <td>americano</td>\n",
       "      <td>ammunition</td>\n",
       "      <td>angel</td>\n",
       "      <td>angels</td>\n",
       "      <td>animal</td>\n",
       "      <td>apart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta weight</th>\n",
       "      <td>-0.0209</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>-0.0069</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>-0.0244</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>-0.0051</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>-0.0172</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>-0.0088</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0        1        2            3          4        5   \\\n",
       "word/feature     1977    99999     adds  advertising  afternoon      age   \n",
       "theta weight  -0.0209  -0.0039  -0.0069      -0.0125    -0.0018  -0.0244   \n",
       "\n",
       "                  6       7       8        9       10       11      12  \\\n",
       "word/feature      ah     aha   aimin      ain      ak    alike    amen   \n",
       "theta weight  0.0235  0.0125  0.0118  -0.1697  0.0118  -0.0051  0.0354   \n",
       "\n",
       "                    13         14          15      16       17      18      19  \n",
       "word/feature  american  americano  ammunition   angel   angels  animal   apart  \n",
       "theta weight    0.0138     0.0438     -0.0172  0.0424  -0.0088  0.0309  0.0315  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test#</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw h(x)</td>\n",
       "      <td>1.7017</td>\n",
       "      <td>0.2724</td>\n",
       "      <td>-0.3703</td>\n",
       "      <td>-0.8951</td>\n",
       "      <td>-0.6691</td>\n",
       "      <td>1.8326</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>1.0930</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4272</td>\n",
       "      <td>-0.7433</td>\n",
       "      <td>1.4334</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>-0.4242</td>\n",
       "      <td>-0.3371</td>\n",
       "      <td>5.5910</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>-0.2279</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sig g(h(x))</td>\n",
       "      <td>0.8458</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.4085</td>\n",
       "      <td>0.2901</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>0.8621</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.3223</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.4433</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>round g(h(x))</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h(x)-y</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           test#       0       1        2        3        4       5       6  \\\n",
       "0       raw h(x)  1.7017  0.2724  -0.3703  -0.8951  -0.6691  1.8326  0.0160   \n",
       "1    sig g(h(x))  0.8458  0.5677   0.4085   0.2901   0.3387  0.8621  0.5040   \n",
       "2  round g(h(x))  1.0000  1.0000   0.0000   0.0000   0.0000  1.0000  1.0000   \n",
       "3         h(x)-y  0.0000  0.0000   0.0000  -1.0000   0.0000  0.0000  1.0000   \n",
       "\n",
       "        7       8 ...       11       12      13      14       15       16  \\\n",
       "0  0.9048  1.0930 ...   2.4272  -0.7433  1.4334  0.1487  -0.4242  -0.3371   \n",
       "1  0.7119  0.7489 ...   0.9189   0.3223  0.8074  0.5371   0.3955   0.4165   \n",
       "2  1.0000  1.0000 ...   1.0000   0.0000  1.0000  1.0000   0.0000   0.0000   \n",
       "3  0.0000  0.0000 ...   0.0000   0.0000  0.0000  1.0000   0.0000   0.0000   \n",
       "\n",
       "       17      18       19   20  \n",
       "0  5.5910  0.4896  -0.2279  ...  \n",
       "1  0.9963  0.6200   0.4433  ...  \n",
       "2  1.0000  1.0000   0.0000  ...  \n",
       "3  0.0000  0.0000   0.0000  ...  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:mymodel errors: 15.0 / 92 = 0.163043\n"
     ]
    }
   ],
   "source": [
    "import tensorGaga as te\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "from myutils import gf\n",
    "from gdsolvers import sigmoid\n",
    "import logging as log\n",
    "\n",
    "### setup variables/placeholders ###\n",
    "tf.reset_default_graph()\n",
    "n_epochs = 2500\n",
    "learning_rate = 0.01\n",
    "\n",
    "X,y,features,rfeatures,testMatrix,testY = te.getGagaTfFormat()   # returns X,y in tf.Variables\n",
    "m = len(testMatrix[0])\n",
    "guesses = np.array([0.01]*n,dtype='float32' ).reshape(-1,1)  \n",
    "\n",
    "theta = tf.Variable(tf.constant(guesses), name='theta')\n",
    "y_pred = tf.sigmoid(tf.matmul(X, theta, name='predictions'))\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    error = y_pred - y                                                  # error vector\n",
    "    ll = tf.reduce_mean(tf.losses.log_loss(y,y_pred), name='log_loss')  # sum of errors w/ -log(x) or -log(1-x)\n",
    "\n",
    "with tf.name_scope(\"gradients\"):\n",
    "    gradients = 2.0/m * tf.matmul(tf.transpose(X), error)               # calculate gradients vector\n",
    "    training_op = tf.assign(theta, theta - learning_rate * gradients)   # to be called later to assign new thetas\n",
    "\n",
    "### run the actual computations ###\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if (epoch % 500 == 0):\n",
    "            print('GD Loop %s Log_Loss %s'%(epoch, ll.eval()))\n",
    "        sess.run(training_op)                                           # assign the gradient values above\n",
    "    best_theta = theta.eval()                                           # get final theta values post loop\n",
    "print('\\ntrained theta weights:', gf(best_theta))               \n",
    "\n",
    "print ('\\nTraining results: ')\n",
    "weightSample = pandas.DataFrame(rfeatures[:20], columns=['word/feature'])\n",
    "weightSample['theta weight'] = gf(best_theta[:20])\n",
    "display(weightSample.transpose())\n",
    "\n",
    "### run test data now ###\n",
    "df = pandas.DataFrame(testMatrix, columns=features)   # new df w/ column names\n",
    "X = df[rfeatures].as_matrix()                # filter out only rfeatures\n",
    "\n",
    "testRes = np.dot(X, best_theta)\n",
    "testResSig = [sigmoid(x) for x in testRes]            \n",
    "testResRound = [round(sigmoid(x),0) for x in testRes]\n",
    "testDiffs = np.array(testResRound) - np.array(testY)\n",
    "\n",
    "testResults = pandas.DataFrame([gf(testRes),gf(testResSig),gf(testResRound), gf(testDiffs)])\n",
    "testResults.insert(0,'test#',['raw h(x)','sig g(h(x))','round g(h(x))','h(x)-y'])\n",
    "display(testResults)     \n",
    "                          \n",
    "log.error('mymodel errors: %s / %s = %f'%(sum([abs(x) for x in testDiffs]),len(testY),sum([abs(x) for x in testDiffs])/len(testY)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of above\n",
    "Using 500 features (reduced w/ kMeans), we ran 70% training to produce the Theta (mymodel guesses array of weights).   \n",
    "\n",
    "- <B>raw h(x)</B>:  are the h(x) totals per feature    \n",
    "- <B>sig g(h(x))</B>:  are the g(h(x)) after running thru the sigmoid function to get 0.0-1.0 values   \n",
    "- <B>round g(h(x))</B>:  rounding g(h(x)) to 0 or 1 to compare vs Y's  \n",
    "- <B>round(g(h(x))-y</B>:  the g(h(x)) - y results -- 0 means prediction was correct.  +1 = false pos, -1 false neg   \n",
    "\n",
    "\n",
    "In summary we have a <B><u>84% correct hit rate</u></B> (15 errors out of 84 test examples).  \n",
    "\n",
    "-----\n",
    "\n",
    "### Higher level TF API - tensorflow.estimator.DNNClassifer()\n",
    "\n",
    "TensorFlow also has higher level API's.  Its almost like 5 lines of code to use the DNNClassifer as per below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sentence</th>\n",
       "      <th>gagaflag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>boysboysboys.txt</td>\n",
       "      <td>\\n\\nHey there sugar baby\\nSaw you twice at the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>wishyouwerehere.txt</td>\n",
       "      <td>\\n\\nIt's funny how things, they change\\nThe cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>thenyoudloveme.txt</td>\n",
       "      <td>\\n\\nWhat if I were to leave you?\\nBut then, yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>cakelikeladygaga.txt</td>\n",
       "      <td>\\n\\nStuntin' all day\\nSwag on a hundred millio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>letsgocrazy.txt</td>\n",
       "      <td>\\n\\nSummon up the mas! Play on the pan!\\nStari...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file                                           sentence  \\\n",
       "40       boysboysboys.txt  \\n\\nHey there sugar baby\\nSaw you twice at the...   \n",
       "24    wishyouwerehere.txt  \\n\\nIt's funny how things, they change\\nThe cl...   \n",
       "262    thenyoudloveme.txt  \\n\\nWhat if I were to leave you?\\nBut then, yo...   \n",
       "178  cakelikeladygaga.txt  \\n\\nStuntin' all day\\nSwag on a hundred millio...   \n",
       "125       letsgocrazy.txt  \\n\\nSummon up the mas! Play on the pan!\\nStari...   \n",
       "\n",
       "     gagaflag  \n",
       "40          1  \n",
       "24          1  \n",
       "262         1  \n",
       "178         1  \n",
       "125         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 250\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tf_logs/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2211c940>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/var/folders/z5/r3lc8_5n7klgg7d5z_tb9sgw0000gn/T/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into tf_logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 95.448944, step = 1\n",
      "INFO:tensorflow:global_step/sec: 77.6374\n",
      "INFO:tensorflow:loss = 14.727301, step = 101 (1.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9792\n",
      "INFO:tensorflow:loss = 5.4160237, step = 201 (1.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.8332\n",
      "INFO:tensorflow:loss = 2.9048536, step = 301 (1.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.0039\n",
      "INFO:tensorflow:loss = 1.7301072, step = 401 (1.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.0075\n",
      "INFO:tensorflow:loss = 0.9354475, step = 501 (1.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.4175\n",
      "INFO:tensorflow:loss = 0.7404134, step = 601 (1.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.7813\n",
      "INFO:tensorflow:loss = 0.70096326, step = 701 (1.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.7513\n",
      "INFO:tensorflow:loss = 0.45348042, step = 801 (1.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2215\n",
      "INFO:tensorflow:loss = 0.41277674, step = 901 (1.202 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into tf_logs/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.37847218.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/var/folders/z5/r3lc8_5n7klgg7d5z_tb9sgw0000gn/T/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-24-15:21:16\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_logs/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-24-15:21:18\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8545455, accuracy_baseline = 0.7090909, auc = 0.8293268, auc_precision_recall = 0.91832805, average_loss = 0.7423719, global_step = 1000, label/mean = 0.7090909, loss = 40.830456, precision = 0.8780488, prediction/mean = 0.7328026, recall = 0.9230769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sentence</th>\n",
       "      <th>gagaflag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>nofloods.txt</td>\n",
       "      <td>\\n\\nI never ever thought I'd live away \\nFrom ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>filthypop.txt</td>\n",
       "      <td>\\n\\nHello! Mr.Radio \\nGot her pink tights \\nAn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>overpoweredbyfunk.txt</td>\n",
       "      <td>\\n\\nIf you ain't reggae for it..funk out!\\nNo-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>herewegoagain.txt</td>\n",
       "      <td>\\n\\nAll my friends are going out, \\nBut I've b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>firefly.txt</td>\n",
       "      <td>\\n\\nI call her Firefly\\nCause, oh, my\\nShe rad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file                                           sentence  \\\n",
       "293           nofloods.txt  \\n\\nI never ever thought I'd live away \\nFrom ...   \n",
       "207          filthypop.txt  \\n\\nHello! Mr.Radio \\nGot her pink tights \\nAn...   \n",
       "183  overpoweredbyfunk.txt  \\n\\nIf you ain't reggae for it..funk out!\\nNo-...   \n",
       "259      herewegoagain.txt  \\n\\nAll my friends are going out, \\nBut I've b...   \n",
       "130            firefly.txt  \\n\\nI call her Firefly\\nCause, oh, my\\nShe rad...   \n",
       "\n",
       "     gagaflag  \n",
       "293         1  \n",
       "207         1  \n",
       "183         0  \n",
       "259         1  \n",
       "130         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 55\n",
      "Test set accuracy: 0.8545454740524292\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorGaga import get_gaga_as_pandas_datasets\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_df, test_df = get_gaga_as_pandas_datasets()\n",
    "display(train_df.head())\n",
    "print (\"Train set size: %d\"%len(train_df))\n",
    "\n",
    "# Training input on the whole training set with no limit on training epochs. (train then test)\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(train_df, train_df[\"gagaflag\"], num_epochs=None, shuffle=True)\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(test_df, test_df[\"gagaflag\"], shuffle=False)\n",
    "\n",
    "# this stuff is magic, there are various text categorizations u can re-use on tfhub.dev for various languages\n",
    "embedded_text_feature_column = hub.text_embedding_column(\n",
    "    key=\"sentence\", module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "\n",
    "# train 3 layer net of input(4000?)-500-100-2 \n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[500, 100],\n",
    "    feature_columns=[embedded_text_feature_column],\n",
    "    model_dir=\"tf_logs/\", n_classes=2,\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "\n",
    "#train and test\n",
    "estimator.train(input_fn=train_input_fn, steps=1000)\n",
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)    # expect ~ .80\n",
    "\n",
    "display(test_df.head())\n",
    "print (\"Test set size: %d\"%len(test_df))\n",
    "print (\"Test set accuracy: {accuracy}\".format(**test_eval_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Amazing !!!</B>  (Other than all this excessive logging I can't trim down w/o eliminating it all)\n",
    "\n",
    "The above example & output shows how easy (but opaque) it is to use a builtin DeepNeuralNetClassifier (DNNClassifer).  You hardly have to do any coding and it works just as well (better) than a hand built classifier.\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "### GPU note\n",
    "\n",
    "I was curious when GPU are faster and since TF supports GPU I was excited.  I found a few things with initial tests (using the default MNIST image database and default example of a 3-4 layer NN using TF):\n",
    "\n",
    "- CPU without MMX is slow (no vector operations on matrix and BGD) - my Atom laptop\n",
    "- CPU w/ MMX is faster (should measure if I can disable MMX somehow) - most laptops\n",
    "- GPU is not always faster (on basic MNIST NN image example it was ~8% faster) - my 1050Ti\n",
    "\n",
    "To setup GPU:\n",
    "- Suggest setup a virtualenv of conda env, so you keep the env clean if you want to compare GPU vs non-GPU\n",
    "- Install TensorFlow (tensorflow-gpu which includes tensorflow - 1.8 in my case)\n",
    "- Install CUDA drivers (9.0 in my case, its compiled for only this version in Windows)\n",
    "- Install Cuda NN DLL (7.1 - just copy DLL after installed to somewhere in path)\n",
    "\n",
    "<B>Note my initial installs were screwed up.  I reinstalled tensorflow after installing CUDA and now its working.   I think using VirtualEnv or Conda Env or Docker would be cleaner.</B>   But now after installing these compatible CUDA drivers my NiceHash for mining is broken!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
